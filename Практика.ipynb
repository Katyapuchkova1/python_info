{"cells":[{"cell_type":"code","source":["!pip install pypdf\n","!pip install pptx"],"metadata":{"id":"bB2RrojpPqaH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702815892964,"user_tz":-180,"elapsed":20643,"user":{"displayName":"Kate Puchkova","userId":"04675053489202082390"}},"outputId":"4c5d2543-322c-4d79-bdd8-8b48ae699a3d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-3.17.2-py3-none-any.whl (277 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.9/277.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-3.17.2\n","\u001b[31mERROR: Could not find a version that satisfies the requirement pptx (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for pptx\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3737,"status":"error","timestamp":1702815911430,"user":{"displayName":"Kate Puchkova","userId":"04675053489202082390"},"user_tz":-180},"id":"L8qdxKbsOIZT","colab":{"base_uri":"https://localhost:8080/","height":383},"outputId":"6fe08144-9906-41a5-be42-90811af68730"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-316fe84f9da6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Pyp'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import requests\n","from requests.adapters import HTTPAdapter\n","from urllib3.util.retry import Retry\n","from bs4 import BeautifulSoup\n","from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n","from Pyp import PdfReader\n","\n","\n","url_main = 'http://recyclebin.ru/BMK/prolog/PrologMet.pdf'\n","uch = requests.get(url_main)\n","with open('uch_1.pdf', 'w') as output_file:\n","  output_file.write(uch.text)\n","\n","from PyPDF2 import PdfReader\n","\n","reader = PdfReader(\"example.pdf\")\n","number_of_pages = len(reader.pages)\n","page = reader.pages[0]\n","text = page.extract_text((0, number_of_pages))\n","\n","\n","letters = ['й, ц, у, к, е, н, г, ш, щ, з, х, ъ, ф, ы, в, а, п, р, о, л, д, ж, э, я, ч, с, м, и, т, ь, б, ю']\n","vowels = ['а', 'е', 'ы', 'у', 'э', 'о', 'я', 'и', 'ю']\n","punctuation = [',', ';', '.', ':', '?', ')', '(', '!']\n","\n","\n"]},{"cell_type":"code","source":["#Получение словаря сложных слов\n","tokenizer=RegexpTokenizer(r'\\n\\w{4,}\\n')\n","url_diff = 'https://mydocx.ru/9-118219.html'\n","vocab = requests.get(url_diff)\n","soup = BeautifulSoup(vocab.content, 'html.parser')\n","text_vocab = soup.get_text()\n","vocab_del = tokenizer.tokenize(text_vocab.lower())\n","vocab = map(lambda x: x.strip('\\n'), vocab_del)\n","vocab_dif = list(vocab)[1:]"],"metadata":{"id":"bo0c3NrwELcK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ONSTANT_SCALING = 4\n","#Метрики удобочитаемости\n","\n","def calc_Flesh_Kincaid_rus(n_syllabes, n_words, n_sent):\n","    \"\"\"Метрика Flesh Kincaid для русского языка\"\"\"\n","    n = 220.755 - 1.315 * (float(n_words) / n_sent) - 50.1 * (float(n_syllabes) / n_words)\n","    return n/CONSTANT_SCALING\n","\n","def calc_Flesh_Kincaid_Grade_rus(n_syllabes, n_words, n_sent):\n","    \"\"\"Метрика Flesh Kincaid Grade для русского языка\"\"\"\n","#    n = 0.59 * (float(n_words) / n_sent) + 6.2 * (float(n_syllabes) / n_words) - 16.59\n","    n = 0.49 * (float(n_words) / n_sent) + 7.3 * (float(n_syllabes) / n_words) - 16.59\n","    return n\n","\n","FLG_X_GRADE = 0.318\n","FLG_Y_GRADE = 14.2\n","FLG_Z_GRADE = 30.5\n","\n","def calc_Flesh_Kincaid_Grade_rus_flex(n_syllabes, n_words, n_sent):\n","    \"\"\"Метрика Flesh Kincaid Grade для русского языка с константными параметрами\"\"\"\n","    if n_words == 0 or n_sent == 0: return 0\n","    n = FLG_X_GRADE * (float(n_words) / n_sent) + FLG_Y_GRADE * (float(n_syllabes) / n_words) - FLG_Z_GRADE\n","    return n/CONSTANT_SCALING\n","\n","CLI_X_GRADE = 0.055\n","CLI_Y_GRADE = 0.35\n","CLI_Z_GRADE = 20.33\n","\n","\n","def calc_Coleman_Liau_index(n_letters, n_words, n_sent):\n","    \"\"\" Метрика Coleman Liau для русского языка с константными параметрами \"\"\"\n","    if n_words == 0: return 0\n","    n = CLI_X_GRADE * (n_letters * (100.0 / n_words)) - CLI_Y_GRADE * (n_sent * (100.0 / n_words)) - CLI_Z_GRADE\n","    return n/CONSTANT_SCALING\n","\n","SMOG_X_GRADE = 1.\n","SMOG_Y_GRADE = 64.6\n","SMOG_Z_GRADE = 0.05\n","\n","def calc_SMOG_index(n_psyl, n_sent):\n","    \"\"\"Метрика SMOG для русского языка с константными параментрами\"\"\"\n","    n = SMOG_X_GRADE * sqrt((float(SMOG_Y_GRADE) / n_sent) * n_psyl) + SMOG_Z_GRADE\n","    return n/CONSTANT_SCALING\n","\n","DC_X_GRADE = 0.552\n","DC_Y_GRADE = 0.273\n","\n","def calc_Dale_Chale_index(n_psyl, n_words, n_sent):\n","    \"\"\"Метрика Dale Chale для русского языка с константным параметрами\"\"\"\n","    n = DC_X_GRADE * (100.0 * n_psyl / n_words) + DC_Y_GRADE * (float(n_words) / n_sent)\n","    return n/CONSTANT_SCALING\n","\n","ARI_X_GRADE = 6.26\n","ARI_Y_GRADE = 0.2805\n","ARI_Z_GRADE = 31.04\n","\n","\n","def calc_ARI_index(n_letters, n_words, n_sent):\n","    \"\"\" Метрика Automated Readability Index (ARI) для русского языка с константными параметрами \"\"\"\n","    if n_words == 0 or n_sent == 0: return 0\n","    n = ARI_X_GRADE * (float(n_letters) / n_words) + ARI_Y_GRADE * (float(n_words) / n_sent) - ARI_Z_GRADE\n","    return n/CONSTANT_SCALING"],"metadata":{"id":"AlrMspOph_gf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgwoNTkE6k29","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702533708569,"user_tz":-180,"elapsed":15,"user":{"displayName":"Kate Puchkova","userId":"04675053489202082390"}},"outputId":"ea9f9471-0166-4109-8745-b6ea331b0f44"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 9, 38, 38, 17, 0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["from string import punctuation\n","import nltk\n","nltk.download('punkt')\n","\n","def count_metrics(text):\n","  \"\"\"Подсчет основных характеристик текста\"\"\"\n","  sents = sent_tokenize(text)\n","  num_sent = len(sents)\n","  num_words = 0\n","  num_letters = 0\n","  num_syl = 0\n","  num_hardwords = 0\n","  for sent in sents:\n","    words = word_tokenize(sent)\n","    words_cleaned =  list(filter(lambda x: x not in punctuation, words))\n","    num_words += len(words_cleaned)\n","    for word in words_cleaned:\n","      if word in vocab_dif: num_hardwords += 1\n","      num_letters += len(word)\n","      for letter in word:\n","        if letter in vowels: num_syl += 1\n","  return (num_sent, num_words, num_letters, num_syl, num_hardwords)\n","\n","text = 'Я был сегодня во дворе. Моих друзей там не было.'\n","count_metrics = count_metrics"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3wrfZh+Oq5bFnrFDE2+DU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}