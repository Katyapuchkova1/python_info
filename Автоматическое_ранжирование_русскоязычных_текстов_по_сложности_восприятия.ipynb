{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! gdown 1br9tHmdccGVzpk0svXNmHxVMh_OF2oZR\n",
        "! pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "id": "bMWbkd5aGb7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "150789f6-073e-4e36-93e9-17d248d327f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1br9tHmdccGVzpk0svXNmHxVMh_OF2oZR\n",
            "To: /content/requirements.txt\n",
            "\r  0% 0.00/328 [00:00<?, ?B/s]\r100% 328/328 [00:00<00:00, 1.30MB/s]\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost==1.0.6 (from -r /content/requirements.txt (line 1))\n",
            "  Downloading catboost-1.0.6-cp310-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==7.1.3 (from -r /content/requirements.txt (line 2))\n",
            "  Downloading pytest-7.1.3-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image==0.19.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 3)) (0.19.3)\n",
            "Collecting h5py==3.7.0 (from -r /content/requirements.txt (line 4))\n",
            "  Downloading h5py-3.7.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt==0.2.7 in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 5)) (0.2.7)\n",
            "Collecting ipywidgets==8.0.2 (from -r /content/requirements.txt (line 6))\n",
            "  Downloading ipywidgets-8.0.2-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras==2.10.0 (from -r /content/requirements.txt (line 7))\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightgbm==3.3.2 (from -r /content/requirements.txt (line 8))\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.5.3 (from -r /content/requirements.txt (line 9))\n",
            "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.6 (from -r /content/requirements.txt (line 10))\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.3.5 (from -r /content/requirements.txt (line 11))\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plotly==5.6.0 (from -r /content/requirements.txt (line 12))\n",
            "  Downloading plotly-5.6.0-py2.py3-none-any.whl (27.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/27.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.7.3 (from -r /content/requirements.txt (line 13))\n",
            "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn==0.12.0 (from -r /content/requirements.txt (line 14))\n",
            "  Downloading seaborn-0.12.0-py3-none-any.whl (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.1/285.1 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.0.2 (from -r /content/requirements.txt (line 15))\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.12.1 (from -r /content/requirements.txt (line 16))\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1 (from -r /content/requirements.txt (line 17))\n",
            "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1 (from -r /content/requirements.txt (line 18))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn==0.5.3 (from -r /content/requirements.txt (line 19))\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xgboost==1.6.2 (from -r /content/requirements.txt (line 20))\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pep8==1.7.1 (from -r /content/requirements.txt (line 21))\n",
            "  Downloading pep8-1.7.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost==1.0.6->-r /content/requirements.txt (line 1)) (0.20.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost==1.0.6->-r /content/requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.3->-r /content/requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.3->-r /content/requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.3->-r /content/requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.3->-r /content/requirements.txt (line 2)) (1.0.0)\n",
            "Collecting py>=1.8.2 (from pytest==7.1.3->-r /content/requirements.txt (line 2))\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.3->-r /content/requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3->-r /content/requirements.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3->-r /content/requirements.txt (line 3)) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3->-r /content/requirements.txt (line 3)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3->-r /content/requirements.txt (line 3)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.3->-r /content/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7->-r /content/requirements.txt (line 5)) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7->-r /content/requirements.txt (line 5)) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7->-r /content/requirements.txt (line 5)) (0.10.9.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (5.5.6)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0 (from ipywidgets==8.0.2->-r /content/requirements.txt (line 6))\n",
            "  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (3.0.7)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2->-r /content/requirements.txt (line 8)) (0.40.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3->-r /content/requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3->-r /content/requirements.txt (line 9)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3->-r /content/requirements.txt (line 9)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3->-r /content/requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3->-r /content/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5->-r /content/requirements.txt (line 11)) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly==5.6.0->-r /content/requirements.txt (line 12)) (8.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r /content/requirements.txt (line 15)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r /content/requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->-r /content/requirements.txt (line 16)) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1->-r /content/requirements.txt (line 17)) (2.27.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3->-r /content/requirements.txt (line 19)) (0.56.4)\n",
            "Collecting pynndescent>=0.5 (from umap-learn==0.5.3->-r /content/requirements.txt (line 19))\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (6.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6))\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn==0.5.3->-r /content/requirements.txt (line 19)) (0.39.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1->-r /content/requirements.txt (line 17)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1->-r /content/requirements.txt (line 17)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1->-r /content/requirements.txt (line 17)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1->-r /content/requirements.txt (line 17)) (3.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (0.2.6)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (5.3.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (23.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel>=4.5.1->ipywidgets==8.0.2->-r /content/requirements.txt (line 6)) (3.3.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=db3a4fb3993700db93f1c08a1404254bc29aeba68a6292aac3f090d0ced2bfe4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=7da004c2d4c2d2e06e2e4d87829c3f08cb30cf094d15d2ee5276b233ee126085\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pep8, keras, widgetsnbextension, tqdm, torch, py, plotly, numpy, jedi, torchvision, scipy, pytest, pandas, matplotlib, h5py, xgboost, seaborn, scikit-learn, catboost, pynndescent, lightgbm, ipywidgets, umap-learn\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.4\n",
            "    Uninstalling widgetsnbextension-3.6.4:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.4\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.13.1\n",
            "    Uninstalling plotly-5.13.1:\n",
            "      Successfully uninstalled plotly-5.13.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.2.2\n",
            "    Uninstalling pytest-7.2.2:\n",
            "      Successfully uninstalled pytest-7.2.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 1.7.5\n",
            "    Uninstalling xgboost-1.7.5:\n",
            "      Successfully uninstalled xgboost-1.7.5\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.12.2\n",
            "    Uninstalling seaborn-0.12.2:\n",
            "      Successfully uninstalled seaborn-0.12.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 3.3.5\n",
            "    Uninstalling lightgbm-3.3.5:\n",
            "      Successfully uninstalled lightgbm-3.3.5\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "tensorflow 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 2.10.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed catboost-1.0.6 h5py-3.7.0 ipywidgets-8.0.2 jedi-0.18.2 keras-2.10.0 lightgbm-3.3.2 matplotlib-3.5.3 numpy-1.21.6 pandas-1.3.5 pep8-1.7.1 plotly-5.6.0 py-1.11.0 pynndescent-0.5.10 pytest-7.1.3 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.12.0 torch-1.12.1 torchvision-0.13.1 tqdm-4.64.1 umap-learn-0.5.3 widgetsnbextension-4.0.7 xgboost-1.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl2BdVLTGT9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15832218-7e49-46c7-a6d2-e862015c56f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def making_dataset(path_files):\n",
        "  strings = []\n",
        "  labels = []\n",
        "  counter=12\n",
        "  for file_ in path_files:\n",
        "    f = open(file_, 'r', encoding='utf8')\n",
        "    lines = f.read()\n",
        "    strings += sent_tokenize(lines)\n",
        "    labels += [counter for i in range(len(sent_tokenize(lines)))]\n",
        "    counter -= 1\n",
        "  return (strings, labels)"
      ],
      "metadata": {
        "id": "s8pG4e8kA3M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = making_dataset(['/content/sample_data/university.txt', '/content/sample_data/11grade.txt', '/content/sample_data/10grade.txt', '/content/sample_data/9grade.txt', \\\n",
        "             '/content/sample_data/8grade.txt', '/content/sample_data/7grade.txt', '/content/sample_data/6grade.txt', \\\n",
        "             '/content/sample_data/5grade.txt', '/content/sample_data/4grade.txt', '/content/sample_data/3grade.txt', \\\n",
        "             '/content/sample_data/2grade.txt', '/content/sample_data/1grade.txt'])\n",
        "\n",
        "\n",
        "counter = CountVectorizer(input='content', token_pattern=r'\\b[а-яА-ЯеЁ]+\\b')\n",
        "\n",
        "data = result[0]\n",
        "\n",
        "data_for_flesh_kinkaid = result[0]\n",
        "\n",
        "labels = result[1]\n",
        "\n",
        "data = counter.fit_transform(data)\n"
      ],
      "metadata": {
        "id": "syNN0eptHXIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=data.toarray(), columns=counter.get_feature_names_out())\n",
        "print(df)\n",
        "\n",
        "pca = PCA()\n",
        "df = pca.fit_transform(df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.25, random_state=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNJZMiklKDpm",
        "outputId": "b40f3949-8fce-42b6-9072-39b899077b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      а  абхазию  аварий  августа  августе  автограф  автографов  автоматом  \\\n",
            "0     0        0       0        0        0         0           0          0   \n",
            "1     0        0       0        0        0         0           0          0   \n",
            "2     1        0       0        0        0         0           0          0   \n",
            "3     0        0       0        0        0         0           0          0   \n",
            "4     0        0       0        0        0         0           0          0   \n",
            "...  ..      ...     ...      ...      ...       ...         ...        ...   \n",
            "2503  0        0       0        0        0         0           0          0   \n",
            "2504  0        0       0        0        0         0           0          0   \n",
            "2505  0        0       0        0        0         0           0          0   \n",
            "2506  0        0       0        0        0         0           0          0   \n",
            "2507  0        0       0        0        0         0           0          0   \n",
            "\n",
            "      адрес  адресованного  ...  ясном  ясности  ясностью  ясные  ясный  \\\n",
            "0         0              0  ...      0        0         0      0      0   \n",
            "1         0              0  ...      0        0         0      0      0   \n",
            "2         0              0  ...      0        0         0      0      0   \n",
            "3         0              0  ...      0        0         0      0      0   \n",
            "4         0              0  ...      0        0         0      0      0   \n",
            "...     ...            ...  ...    ...      ...       ...    ...    ...   \n",
            "2503      0              0  ...      0        0         0      0      0   \n",
            "2504      0              0  ...      0        0         0      0      0   \n",
            "2505      0              0  ...      0        0         0      0      0   \n",
            "2506      0              0  ...      0        0         0      0      0   \n",
            "2507      0              0  ...      0        0         0      0      0   \n",
            "\n",
            "      ясным  ясных  ястреб  ящериц  ящики  \n",
            "0         0      0       0       0      0  \n",
            "1         0      0       0       0      0  \n",
            "2         0      0       0       0      0  \n",
            "3         0      0       0       0      0  \n",
            "4         0      0       0       0      0  \n",
            "...     ...    ...     ...     ...    ...  \n",
            "2503      0      0       0       0      0  \n",
            "2504      0      0       0       0      0  \n",
            "2505      0      0       0       0      0  \n",
            "2506      0      0       0       0      0  \n",
            "2507      0      0       0       0      0  \n",
            "\n",
            "[2508 rows x 10806 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegression(penalty='l2', multi_class='multinomial', C=1.0)"
      ],
      "metadata": {
        "id": "5Y6AifwOP2G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR.fit(X_train, y_train)\n",
        "predictions = LR.predict(X=X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "gkx749rlTON6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MAE на тестовой выборке:\", mean_absolute_error(predictions, y_test))\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNlrJ922Xzul",
        "outputId": "ddab0a48-c53f-49a9-a6a1-231ad97059dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE на тестовой выборке: 2.4322169059011163\n",
            "(627, 2508)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Flesh_kinkide_coeffs\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "\n",
        "def count_syllables(word):\n",
        "    count_syl = 0\n",
        "    for i in word:\n",
        "      if i in ['а', 'е', 'ё', 'и', 'о', 'у', 'э', 'ю', 'я']:\n",
        "        count_syl += 1\n",
        "      return count_syl\n",
        "\n",
        "\n",
        "def counting_parameters(strings, labels):\n",
        "    X = np.empty((len(strings), 2))\n",
        "    Y = np.empty((len(strings)))\n",
        "    num_sent = 0\n",
        "    label = 0\n",
        "    for sent in strings:\n",
        "      words = regexp_tokenize(sent.lower(), \"[а-яё]+\")\n",
        "      count_words = len(words)\n",
        "      count_syl = 0\n",
        "      for w in words:\n",
        "        count_syl += count_syllables(w)\n",
        "      if(count_words > 0):\n",
        "        X[num_sent, 0] = count_words\n",
        "        X[num_sent, 1] = count_syl/count_words\n",
        "        Y[num_sent] = labels[label]\n",
        "        num_sent += 1\n",
        "      label += 1\n",
        "    return (X[:num_sent, :], Y[:num_sent])\n",
        "\n"
      ],
      "metadata": {
        "id": "ubriycYueFMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = counting_parameters(data_for_flesh_kinkaid, labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(result[0], result[1], test_size=0.25, random_state=16)\n",
        "LR.fit(X_train, y_train)\n",
        "predictions = LR.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHjVOQaFz8Ji",
        "outputId": "aaf0a339-13f2-47ac-d93b-792bb89a4e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MAE на тестовой выборке(Тест Флэша-Кинкайда) - логистическая регрессия:\", mean_absolute_error(predictions, y_test))\n",
        "print(\"Коэффициенты для теста Флэша-Кинкайда - логистическая регрессия:\")\n",
        "print(LR.coef_)\n",
        "print(\"Свободный член\", LR.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yyDzMNr0ixR",
        "outputId": "23945a14-89e3-4c12-903a-2b4cf29c60ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE на тестовой выборке(Тест Флэша-Кинкайда) - логистическая регрессия: 2.8298555377207064\n",
            "Коэффициенты для теста Флэша-Кинкайда - логистическая регрессия:\n",
            "[[-0.31057081  0.41454511]\n",
            " [ 0.08283995  0.5677827 ]\n",
            " [-0.15033415 -0.26366596]\n",
            " [-0.08988008  0.75212394]\n",
            " [-0.09475663 -0.36969104]\n",
            " [ 0.03171631 -0.35702043]\n",
            " [ 0.05713094 -0.46932586]\n",
            " [ 0.05844729 -0.55096304]\n",
            " [ 0.11350564  0.5268786 ]\n",
            " [ 0.09120793  0.12936996]\n",
            " [ 0.08034951 -0.20869695]\n",
            " [ 0.13034411 -0.17133703]]\n",
            "Свободный член [ 2.6451799  -2.19136292  2.04302077  1.34301156  1.21735278 -0.20098818\n",
            " -0.72996977 -0.21984729 -1.42620476 -0.3942918  -0.18326534 -1.90263496]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "Ue94AeNvazYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinReg = LinearRegression()\n",
        "LinReg.fit(X_train, y_train)\n",
        "predictions = LinReg.predict(X_test)\n",
        "print(\"MAE на тестовой выборке(Тест Флэша-Кинкайда) - линейная регрессия:\", mean_absolute_error(predictions, y_test))\n",
        "print(\"Коэффициенты для теста Флэша-Кинкайда - линейная регрессия:\" )\n",
        "print(LinReg.coef_)\n",
        "print(\"Свободный член\", LinReg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4s1i6ggbfNV",
        "outputId": "c65b707a-cc27-4cb4-84fa-e4835bdd55bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE на тестовой выборке(Тест Флэша-Кинкайда) - линейная регрессия: 2.641403947824825\n",
            "Коэффициенты для теста Флэша-Кинкайда - линейная регрессия:\n",
            "[ 0.18786239 -0.27667395]\n",
            "Свободный член 4.4471827243718565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Тест Колман-Лиау\n",
        "def colman_liau(strings, labels):\n",
        "  count_words = 0\n",
        "  num_sent = 0\n",
        "  count_syl = 0\n",
        "  count_sent = 0\n",
        "  str_mat = 0\n",
        "  X = np.empty((len(strings), 2))\n",
        "  Y = np.empty(len(strings))\n",
        "  curr_lab = 12\n",
        "  for sent in strings:\n",
        "    if labels[num_sent] != curr_lab:\n",
        "      count_syl = 0\n",
        "      count_words = 0\n",
        "      curr_lab -= 1\n",
        "      count_sent = 0\n",
        "    words = regexp_tokenize(sent.lower(), \"[а-яё]+\")\n",
        "    count_words += len(words)\n",
        "    for w in words:\n",
        "      count_syl += len(w)\n",
        "    if (count_words >= 100):\n",
        "      X[str_mat, 0] = num_sent\n",
        "      X[str_mat, 1] = count_syl\n",
        "      Y[str_mat] = labels[num_sent]\n",
        "      count_words = 0\n",
        "      count_syl = 0\n",
        "      count_sent = 0\n",
        "      str_mat += 1\n",
        "    count_sent += 1\n",
        "    num_sent += 1\n",
        "  return (X[:str_mat], Y[:str_mat])"
      ],
      "metadata": {
        "id": "Jc8Ght36htew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_colman = data_for_flesh_kinkaid\n",
        "result = colman_liau(data_colman, labels)\n"
      ],
      "metadata": {
        "id": "2VjnztzDmMxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X = result[0]\n",
        "Y = result[1]\n",
        "S_S = StandardScaler()\n",
        "S_S.fit_transform(X)\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T9hu9tSnpjD",
        "outputId": "5bc52aee-2b4e-43d6-95b4-862c8ee49e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=16)"
      ],
      "metadata": {
        "id": "WwaonqkqmtOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LinearRegression()\n",
        "LR.fit(X_train, y_train)\n",
        "predictions = LR.predict(X_test)"
      ],
      "metadata": {
        "id": "iHR3_wpgnqPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MAE на тестовой выборке(Тест Колман-Лиау) - линейная регрессия:\", mean_absolute_error(predictions, y_test))\n",
        "print(\"Коэффициенты для теста Колман-Лиау - линейная регрессия:\" )\n",
        "print(LinReg.coef_)\n",
        "print(\"Свободный член\", LinReg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPz00QS7nLjH",
        "outputId": "cce1bc98-61c1-4b22-bb4e-98fdc4b122d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE на тестовой выборке(Тест Колман-Лиау) - линейная регрессия: 0.34114151120148833\n",
            "Коэффициенты для теста Колман-Лиау - линейная регрессия:\n",
            "[ 0.18786239 -0.27667395]\n",
            "Свободный член 4.4471827243718565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Формула Дэйла-Чалл\n",
        "def deil_chall(strings, labels):\n",
        "    f = open(\"/content/sample_data/difficult_words.txt\", 'r', encoding='utf8')\n",
        "    lines = f.read()\n",
        "    diff_list = regexp_tokenize(lines.lower(), \"[а-яё]+\")\n",
        "    X = np.empty((len(strings), 2))\n",
        "    Y = np.empty((len(strings)))\n",
        "    num_sent = 0\n",
        "    label = 0\n",
        "    diff_words = 0\n",
        "    for sent in strings:\n",
        "      words = regexp_tokenize(sent.lower(), \"[а-яё]+\")\n",
        "      count_words = len(words)\n",
        "      count_syl = 0\n",
        "      diff_words = 0\n",
        "      for w in words:\n",
        "        count_syl += count_syllables(w)\n",
        "        if w in diff_list: diff_words += 1\n",
        "      if(count_words > 0):\n",
        "        X[num_sent, 0] = diff_words/count_words\n",
        "        X[num_sent, 1] = count_words\n",
        "        Y[num_sent] = labels[label]\n",
        "        num_sent += 1\n",
        "      label += 1\n",
        "    return (X[:num_sent, :], Y[:num_sent])\n"
      ],
      "metadata": {
        "id": "qM8VJKYhw2Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_chal = data_colman\n",
        "result = deil_chall(data_chal, labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(result[0], result[1], test_size=0.25, random_state=16)"
      ],
      "metadata": {
        "id": "C-OsZVZBzIRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LinearRegression()\n",
        "LR.fit(X_train, y_train)\n",
        "predictions = LR.predict(X_test)"
      ],
      "metadata": {
        "id": "_DtVVwS8z6Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MAE на тестовой выборке(Формула Дэйла-Чалл) - линейная регрессия:\", mean_absolute_error(predictions, y_test))\n",
        "print(\"Коэффициенты для формулы Дэйла-Чалл - линейная регрессия:\" )\n",
        "print(LinReg.coef_)\n",
        "print(\"Свободный член\", LinReg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYzboU19z8R9",
        "outputId": "57cec3e9-b8e7-4ffc-9c30-e09e7cec97ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE на тестовой выборке(Формула Дэйла-Чалл) - линейная регрессия: 2.6431360706285645\n",
            "Коэффициенты для формулы Дэйла-Чалл - линейная регрессия:\n",
            "[ 0.18786239 -0.27667395]\n",
            "Свободный член 4.4471827243718565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Автоматизированный индекс удобочитаемости\n",
        "\n",
        "def auto_r(strings, labels):\n",
        "    X = np.empty((len(strings), 2))\n",
        "    Y = np.empty((len(strings)))\n",
        "    num_sent = 0\n",
        "    label = 0\n",
        "    c_characters = 0\n",
        "    for sent in strings:\n",
        "      words = regexp_tokenize(sent.lower(), \"[а-яё]+\")\n",
        "      count_words = len(words)\n",
        "      for w in words:\n",
        "        c_characters += len(w)\n",
        "      if(count_words > 0):\n",
        "        X[num_sent, 0] = c_characters/count_words\n",
        "        X[num_sent, 1] = count_words\n",
        "        Y[num_sent] = labels[label]\n",
        "        num_sent += 1\n",
        "      label += 1\n",
        "      c_characters = 0\n",
        "    return (X[:num_sent, :], Y[:num_sent])"
      ],
      "metadata": {
        "id": "gQj8RDI90QVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_auto = data_colman\n",
        "result = auto_r(data_auto, labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(result[0], result[1], test_size=0.25, random_state=16)"
      ],
      "metadata": {
        "id": "SQeSQJbf1Soq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LinearRegression()\n",
        "LR.fit(X_train, y_train)\n",
        "predictions = LR.predict(X_test)"
      ],
      "metadata": {
        "id": "Mcgo6ZyR1jn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MAE на тестовой выборке(Автоматизированный индекс удобочитаемости) - линейная регрессия:\", mean_absolute_error(predictions, y_test))\n",
        "print(\"Коэффициенты для автоматизированного индекса удобочитаемости - линейная регрессия:\" )\n",
        "print(LinReg.coef_)\n",
        "print(\"Свободный член\", LinReg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5whLEVXr1meY",
        "outputId": "20cc651b-5339-46f6-8e8f-8d7348254f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE на тестовой выборке(Автоматизированный индекс удобочитаемости) - линейная регрессия: 2.6499192823154836\n",
            "Коэффициенты для автоматизированного индекса удобочитаемости - линейная регрессия:\n",
            "[ 0.18786239 -0.27667395]\n",
            "Свободный член 4.4471827243718565\n"
          ]
        }
      ]
    }
  ]
}